#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import feedparser
import sqlite3
import requests
from datetime import datetime
import time
import sys
import os

def parse_date(date_str):
    """ç»Ÿä¸€å°†å„ç§æ—¥æœŸæ ¼å¼è½¬æ¢ä¸ºå­—ç¬¦ä¸²"""
    if not date_str:
        return datetime.now().isoformat()
    
    # å¦‚æœå·²ç»æ˜¯datetimeå¯¹è±¡
    if isinstance(date_str, datetime):
        return date_str.isoformat()
    
    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æ
    try:
        # å¤„ç†å¸¸è§çš„RSSæ—¥æœŸæ ¼å¼
        # Sun, 22 Feb 2026 20:37:45 GMT
        if 'GMT' in date_str:
            # å»æ‰GMTå¹¶è§£æ
            dt = datetime.strptime(date_str.replace(' GMT', ''), '%a, %d %b %Y %H:%M:%S')
            return dt.isoformat()
        # 2026-02-22 15:00:00  +0800
        elif '+0800' in date_str:
            dt = datetime.strptime(date_str.split('+')[0].strip(), '%Y-%m-%d %H:%M:%S')
            return dt.isoformat()
        else:
            # å°è¯•ç›´æ¥è§£æISOæ ¼å¼
            return datetime.fromisoformat(date_str).isoformat()
    except:
        # å¦‚æœéƒ½å¤±è´¥ï¼Œè¿”å›å½“å‰æ—¶é—´
        return datetime.now().isoformat()

def fetch_articles():
    """æŠ“å–æ–‡ç« çš„ä¸»å‡½æ•°ï¼Œä¿®å¤äº†æ—¥æœŸæ¯”è¾ƒbug"""
    conn = sqlite3.connect('data/ai_rss.db')
    c = conn.cursor()
    
    # è·å–æ‰€æœ‰æºé…ç½®
    try:
        from config import RSS_FEEDS
        feeds = RSS_FEEDS
    except ImportError:
        print("âš ï¸ æ— æ³•å¯¼å…¥config.pyï¼Œä½¿ç”¨æµ‹è¯•æº")
        feeds = [
            {"name": "InfoQ", "url": "https://www.infoq.cn/feed", "priority": "high"},
            {"name": "36æ°ª", "url": "https://www.36kr.com/feed", "priority": "medium"},
        ]
    
    print(f"\nâœ… å¼€å§‹æŠ“å– {len(feeds)} ä¸ªæº")
    total_new = 0
    
    for i, feed in enumerate(feeds, 1):
        if feed.get("enabled", True) is False:
            print(f"\n[{i}/{len(feeds)}] {feed.get('name')} (å·²ç¦ç”¨ï¼Œè·³è¿‡)")
            continue
        feed_name = feed["name"]
        feed_url = feed["url"]
        
        print(f"\n[{i}/{len(feeds)}] {feed_name}")
        
        try:
            # è·å–è¯¥æºçš„æœ€æ–°æ–‡ç« æ—¶é—´
            c.execute('''
                SELECT MAX(published_date) FROM articles 
                WHERE feed_name = ?
            ''', (feed_name,))
            result = c.fetchone()
            latest_time = result[0] if result and result[0] else None
            print(f"  â”œâ”€ ğŸ“… ä¸Šæ¬¡æœ€æ–°æ–‡ç« : {latest_time}")
            
            # æŠ“å–RSS
            print(f"  â”œâ”€ æŠ“å– {feed_url}")
            feed_data = feedparser.parse(feed_url)
            
            if hasattr(feed_data, 'status') and feed_data.status != 200:
                print(f"  â”œâ”€ âš ï¸ HTTPçŠ¶æ€ç : {feed_data.status}")
            
            entries = feed_data.entries[:30]  # å–æœ€æ–°30æ¡
            print(f"  â”œâ”€ RSSåŒ…å« {len(entries)} ç¯‡æ–‡ç« ")
            
            new_count = 0
            
            for entry in entries:
                # æå–æ•°æ®
                title = entry.get('title', '')
                link = entry.get('link', '')
                
                # å…³é”®ä¿®å¤ï¼šç»Ÿä¸€è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼
                published = parse_date(entry.get('published', ''))
                
                # å¢é‡åˆ¤æ–­ï¼šç°åœ¨éƒ½æ˜¯å­—ç¬¦ä¸²ï¼Œå¯ä»¥æ¯”è¾ƒäº†
                if latest_time and published <= latest_time:
                    # print(f"  â”œâ”€ è·³è¿‡æ—§æ–‡ç« : {title[:30]}...")
                    continue
                
                # æ’å…¥æ•°æ®åº“
                try:
                    c.execute('''
                        INSERT OR REPLACE INTO articles 
                        (feed_name, article_title, article_link, published_date, 
                         last_seen, fulltext_fetched)
                        VALUES (?, ?, ?, ?, ?, ?)
                    ''', (
                        feed_name, 
                        title, 
                        link, 
                        published,
                        datetime.now().isoformat(),
                        0
                    ))
                    new_count += 1
                    print(f"  â”œâ”€ âœ… æ–°å¢: {title[:50]}...")
                    
                except Exception as e:
                    print(f"  â”œâ”€ âŒ æ’å…¥å¤±è´¥: {e}")
                    print(f"      é“¾æ¥: {link}")
            
            # æäº¤è¯¥æºçš„ç»“æœ
            conn.commit()
            print(f"  â”œâ”€ âœ¨ æ–°å¢ {new_count} ç¯‡æ–‡ç« ")
            total_new += new_count
            
        except Exception as e:
            print(f"  â”œâ”€ âŒ å¤„ç†å‡ºé”™: {e}")
            conn.rollback()
    
    print(f"\nğŸ‰ å…¨éƒ¨å®Œæˆï¼Œå…±æ–°å¢ {total_new} ç¯‡æ–‡ç« ")
    conn.close()
    return total_new

def fetch_fulltext():
    """æŠ“å–å…¨æ–‡"""
    conn = sqlite3.connect('data/ai_rss.db')
    c = conn.cursor()
    
    c.execute('''
        SELECT id, article_link FROM articles 
        WHERE fulltext_fetched = 0 AND article_link IS NOT NULL
        LIMIT 50
    ''')
    
    articles = c.fetchall()
    print(f"\nğŸ“– éœ€è¦æŠ“å–å…¨æ–‡: {len(articles)} ç¯‡")
    
    for article_id, link in articles:
        try:
            print(f"   æŠ“å–: {link}")
            # è¿™é‡Œæ·»åŠ æ‚¨çš„å…¨æ–‡æŠ“å–é€»è¾‘
            c.execute('''
                UPDATE articles 
                SET fulltext_fetched = 1, 
                    last_seen = ?
                WHERE id = ?
            ''', (datetime.now().isoformat(), article_id))
            conn.commit()
        except Exception as e:
            print(f"   âŒ æŠ“å–å¤±è´¥: {e}")
            conn.rollback()
    
    conn.close()

if __name__ == '__main__':
    print("ğŸš€ å¯åŠ¨ä¿®å¤ç‰ˆ fetcherï¼ˆæ—¥æœŸæ¯”è¾ƒå·²ä¿®å¤ï¼‰")
    
    if len(sys.argv) > 1 and sys.argv[1] == '--fulltext':
        fetch_fulltext()
    else:
        fetch_articles()
    
    print("âœ… å®Œæˆ")
